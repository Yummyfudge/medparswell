# MedParsWell

**MedParsWell** is a modular FastAPI-based API and service layer for wrapping CLI-based LLM backends such as `ik_llama.cpp`. It is designed to expose model metadata and options via schemas compatible with downstream tools like Gradio and future UI layers.

## Features

- ğŸ§  LLM inference shell wrapper (supports `ik_llama.cpp`)
- ğŸ› ï¸ Schema-driven API metadata exposure (Pydantic v2, with `json_schema_extra` for Gradio compatibility)
- ğŸªµ Configurable logging with console and file output
- ğŸ” Designed for compatibility with Gradio dynamic forms
- ğŸ“¡ Remote execution support via subprocess shell calls
- ğŸ“¦ Structured, extensible architecture with FastAPI
- ğŸ§ª Testable CLI inference layer with mocking support

## Quickstart

```bash
git clone git@github.com:Yummyfudge/medparswell.git
cd medparswell

# Create environment
conda env create -f environment.yml
conda activate medparswell

# Launch dev server
uvicorn app.main:app --reload
```

## Directory Structure

```
medparswell/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ logging_config.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ services/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ services/
â”‚   â””â”€â”€ conftest.py
â”œâ”€â”€ notes/
â”œâ”€â”€ docs/
â”œâ”€â”€ to_linux.sh
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md
```

## Run Tests

```bash
pytest -v
```

Supports full mocking and isolated CLI testing. One integration test is skipped unless the FastAPI server is running.

## Roadmap

- [x] Route scaffolding & health endpoints
- [x] API schema metadata exposure
- [x] CLI integration with `ik_llama.cpp`
- [x] Add Gradio UI compatibility
- [x] Support full CLI argument mapping
- [ ] Implement request batching & streaming
- [ ] Local/remote inference split
- [ ] Add persistent slot caching
- [ ] CLI embedding-only mode support

## License

This project is licensed under the MIT License.

## Acknowledgements

This project interfaces with the following external tools:

- [`ik_llama.cpp`](https://github.com/ikawrakow/ik_llama.cpp): A high-performance fork of `llama.cpp` for running GGUF models locally. Used by MedParsWell as the backend inference engine via CLI subprocess calls. See their repository for licensing and attribution details.
- The [Level1Techs community](https://forum.level1techs.com) and Wendell for the inspiration, ideas, and support that helped shape the goals of this project.